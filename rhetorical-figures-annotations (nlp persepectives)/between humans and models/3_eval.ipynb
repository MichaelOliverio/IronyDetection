{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per aprire i file in una directory e ordinarli\n",
    "def open_files(directory):\n",
    "    files = os.listdir(directory)\n",
    "    files.sort()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_sig(x, sig=3):\n",
    "    if isinstance(x, (float, int)):\n",
    "        return float(f\"{x:.{sig}g}\")\n",
    "    return x\n",
    "\n",
    "def format_report(report_dict):\n",
    "    rounded = {}\n",
    "    for label, metrics in report_dict.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            rounded[label] = {k: round_sig(v) for k, v in metrics.items()}\n",
    "        else:\n",
    "            rounded[label] = round_sig(metrics)\n",
    "    return rounded\n",
    "\n",
    "def print_formatted_report(report_dict):\n",
    "    print(\"\\nðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\")\n",
    "    labels = [label for label in report_dict if label not in ('accuracy', 'macro avg', 'weighted avg')]\n",
    "    header = f\"{'Label':<20} {'Prec':>8} {'Rec':>8} {'F1':>8} {'Support':>8}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for label in labels + ['macro avg', 'weighted avg']:\n",
    "        row = report_dict[label]\n",
    "        print(f\"{label:<20} {row['precision']:>8.3f} {row['recall']:>8.3f} {row['f1-score']:>8.3f} {row['support']:>8.0f}\")\n",
    "    print(f\"{'Accuracy':<20} {'':>8} {'':>8} {'':>8} {report_dict['accuracy']:>8.3f}\")\n",
    "\n",
    "def calculate_metrics(df, print_confusion=False):\n",
    "    # Assumiamo che prediction e actual siano le colonne corrette\n",
    "    df['extracted_prediction'] = df['prediction'].astype(str)\n",
    "    df['rhetorical_figure'] = df['actual'].astype(str)  # assicurati che 'actual' sia la colonna giusta\n",
    "    \n",
    "    # Rimuoviamo eventuali righe con valori mancanti nelle due colonne (evita errori)\n",
    "    df_clean = df\n",
    "\n",
    "    if print_confusion:\n",
    "        print(f\"\\nðŸ§© Matrice di confusione:\")\n",
    "        confusion = pd.crosstab(df_clean['rhetorical_figure'], df_clean['extracted_prediction'],\n",
    "                                rownames=['Actual'], colnames=['Predicted'])\n",
    "        print(confusion)\n",
    "\n",
    "    report = classification_report(df_clean['rhetorical_figure'], df_clean['extracted_prediction'], output_dict=True, zero_division=0)\n",
    "    return report\n",
    "\n",
    "def average_reports(reports):\n",
    "    avg_report = {}\n",
    "    keys = reports[0].keys()\n",
    "\n",
    "    for key in keys:\n",
    "        if isinstance(reports[0][key], dict):\n",
    "            avg_report[key] = {}\n",
    "            for metric in reports[0][key]:\n",
    "                values = [r[key].get(metric, 0.0) for r in reports if key in r]\n",
    "                avg_report[key][metric] = np.mean(values)\n",
    "        else:  # accuracy\n",
    "            values = [r.get(key, 0.0) for r in reports]\n",
    "            avg_report[key] = np.mean(values)\n",
    "\n",
    "    return avg_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.261    0.500    0.343       12\n",
      "CONTEXT SHIFT           0.438    0.269    0.333       26\n",
      "EUPHEMISM               0.500    0.200    0.286        5\n",
      "FALSE ASSERTION         0.333    0.111    0.167        9\n",
      "HYPERBOLE               0.500    0.167    0.250        6\n",
      "OTHER                   0.385    0.417    0.400       12\n",
      "OXYMORON                0.067    0.500    0.118        2\n",
      "RHETORICAL QUESTION     0.625    0.500    0.556       10\n",
      "macro avg               0.388    0.333    0.306       82\n",
      "weighted avg            0.415    0.329    0.339       82\n",
      "Accuracy                                           0.329\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'generation_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.217    0.556    0.312        9\n",
      "CONTEXT SHIFT           0.250    0.222    0.235       18\n",
      "EUPHEMISM               0.500    0.167    0.250        6\n",
      "FALSE ASSERTION         0.333    0.091    0.143       11\n",
      "HYPERBOLE               0.500    0.111    0.182        9\n",
      "OTHER                   0.308    0.267    0.286       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.500    0.308    0.381       13\n",
      "macro avg               0.326    0.215    0.224       82\n",
      "weighted avg            0.350    0.244    0.256       82\n",
      "Accuracy                                           0.244\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.304    0.412    0.350       17\n",
      "CONTEXT SHIFT           0.375    0.214    0.273       28\n",
      "EUPHEMISM               0.500    0.071    0.125       14\n",
      "FALSE ASSERTION         0.000    0.000    0.000        4\n",
      "HYPERBOLE               0.500    0.250    0.333        4\n",
      "OTHER                   0.000    0.000    0.000        3\n",
      "OXYMORON                0.067    1.000    0.125        1\n",
      "RHETORICAL QUESTION     0.500    0.364    0.421       11\n",
      "macro avg               0.281    0.289    0.203       82\n",
      "weighted avg            0.369    0.244    0.261       82\n",
      "Accuracy                                           0.244\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.217    0.455    0.294       11\n",
      "CONTEXT SHIFT           0.250    0.235    0.242       17\n",
      "EUPHEMISM               0.500    0.250    0.333        4\n",
      "FALSE ASSERTION         0.333    0.067    0.111       15\n",
      "HYPERBOLE               0.500    0.125    0.200        8\n",
      "OTHER                   0.154    0.133    0.143       15\n",
      "OXYMORON                0.067    0.200    0.100        5\n",
      "RHETORICAL QUESTION     0.125    0.143    0.133        7\n",
      "macro avg               0.268    0.201    0.195       82\n",
      "weighted avg            0.258    0.195    0.189       82\n",
      "Accuracy                                           0.195\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.391    0.562    0.462       16\n",
      "CONTEXT SHIFT           0.438    0.389    0.412       18\n",
      "EUPHEMISM               0.000    0.000    0.000        7\n",
      "FALSE ASSERTION         0.333    0.053    0.091       19\n",
      "HYPERBOLE               0.500    0.100    0.167       10\n",
      "OTHER                   0.231    0.500    0.316        6\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.250    0.400    0.308        5\n",
      "macro avg               0.268    0.251    0.219       82\n",
      "weighted avg            0.343    0.280    0.264       82\n",
      "Accuracy                                           0.280\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.217    0.556    0.312        9\n",
      "CONTEXT SHIFT           0.250    0.222    0.235       18\n",
      "EUPHEMISM               0.500    0.167    0.250        6\n",
      "FALSE ASSERTION         0.333    0.091    0.143       11\n",
      "HYPERBOLE               0.500    0.111    0.182        9\n",
      "OTHER                   0.308    0.267    0.286       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.500    0.308    0.381       13\n",
      "macro avg               0.326    0.215    0.224       82\n",
      "weighted avg            0.350    0.244    0.256       82\n",
      "Accuracy                                           0.244\n",
      "\n",
      "ðŸ“Š Report per il modello 'LLaMAntino-3-ANITA-8B-Inst-DPO-ITA_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.217    0.333    0.263       15\n",
      "CONTEXT SHIFT           0.125    0.222    0.160        9\n",
      "EUPHEMISM               0.500    0.143    0.222        7\n",
      "FALSE ASSERTION         0.333    0.071    0.118       14\n",
      "HYPERBOLE               0.500    0.091    0.154       11\n",
      "OTHER                   0.154    0.143    0.148       14\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.500    0.364    0.421       11\n",
      "macro avg               0.291    0.171    0.186       82\n",
      "weighted avg            0.313    0.195    0.207       82\n",
      "Accuracy                                           0.195\n",
      "Processing model: Llama-3.1-8B-Instruct-decoding-1 .csv_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct-decoding-1 .csv_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.261    0.500    0.343       12\n",
      "CONTEXT SHIFT           0.214    0.115    0.150       26\n",
      "EUPHEMISM               0.333    0.400    0.364        5\n",
      "FALSE ASSERTION         0.000    0.000    0.000        9\n",
      "HYPERBOLE               1.000    0.167    0.286        6\n",
      "INTERROGATIVE           0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       12\n",
      "OXYMORON                0.000    0.000    0.000        2\n",
      "RHETORICAL QUESTION     0.381    0.800    0.516       10\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.219    0.198    0.166       82\n",
      "weighted avg            0.246    0.244    0.204       82\n",
      "Accuracy                                           0.244\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct-decoding-1 .csv_predictions.csv' con file 'generation_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.261    0.667    0.375        9\n",
      "CONTEXT SHIFT           0.214    0.167    0.188       18\n",
      "EUPHEMISM               0.333    0.333    0.333        6\n",
      "FALSE ASSERTION         0.167    0.091    0.118       11\n",
      "HYPERBOLE               1.000    0.111    0.200        9\n",
      "INTERROGATIVE           0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.524    0.846    0.647       13\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.250    0.221    0.186       82\n",
      "weighted avg            0.315    0.293    0.247       82\n",
      "Accuracy                                           0.293\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct-decoding-1 .csv_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.304    0.412    0.350       17\n",
      "CONTEXT SHIFT           0.357    0.179    0.238       28\n",
      "EUPHEMISM               0.333    0.143    0.200       14\n",
      "FALSE ASSERTION         0.167    0.250    0.200        4\n",
      "HYPERBOLE               1.000    0.250    0.400        4\n",
      "INTERROGATIVE           0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000        3\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.381    0.727    0.500       11\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.254    0.196    0.189       82\n",
      "weighted avg            0.350    0.293    0.284       82\n",
      "Accuracy                                           0.293\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct-decoding-1 .csv_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.304    0.636    0.412       11\n",
      "CONTEXT SHIFT           0.143    0.118    0.129       17\n",
      "EUPHEMISM               0.333    0.500    0.400        4\n",
      "FALSE ASSERTION         0.333    0.133    0.190       15\n",
      "HYPERBOLE               1.000    0.125    0.222        8\n",
      "INTERROGATIVE           0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.000    0.000    0.000        5\n",
      "RHETORICAL QUESTION     0.238    0.714    0.357        7\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.235    0.223    0.171       82\n",
      "weighted avg            0.266    0.232    0.189       82\n",
      "Accuracy                                           0.232\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct-decoding-1 .csv_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.348    0.500    0.410       16\n",
      "CONTEXT SHIFT           0.143    0.111    0.125       18\n",
      "EUPHEMISM               0.167    0.143    0.154        7\n",
      "FALSE ASSERTION         0.500    0.158    0.240       19\n",
      "HYPERBOLE               1.000    0.100    0.182       10\n",
      "INTERROGATIVE           0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000        6\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.238    1.000    0.385        5\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.240    0.201    0.150       82\n",
      "weighted avg            0.366    0.244    0.222       82\n",
      "Accuracy                                           0.244\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct-decoding-1 .csv_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.261    0.667    0.375        9\n",
      "CONTEXT SHIFT           0.214    0.167    0.188       18\n",
      "EUPHEMISM               0.333    0.333    0.333        6\n",
      "FALSE ASSERTION         0.167    0.091    0.118       11\n",
      "HYPERBOLE               1.000    0.111    0.200        9\n",
      "INTERROGATIVE           0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.524    0.846    0.647       13\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.250    0.221    0.186       82\n",
      "weighted avg            0.315    0.293    0.247       82\n",
      "Accuracy                                           0.293\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct-decoding-1 .csv_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.304    0.467    0.368       15\n",
      "CONTEXT SHIFT           0.071    0.111    0.087        9\n",
      "EUPHEMISM               0.333    0.286    0.308        7\n",
      "FALSE ASSERTION         0.500    0.214    0.300       14\n",
      "HYPERBOLE               1.000    0.091    0.167       11\n",
      "INTERROGATIVE           0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       14\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.429    0.818    0.562       11\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.264    0.199    0.179       82\n",
      "weighted avg            0.369    0.280    0.252       82\n",
      "Accuracy                                           0.280\n",
      "Processing model: Llama-3.1-8B-Instruct_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.211    0.333    0.258       12\n",
      "CONTEXT SHIFT           0.400    0.231    0.293       26\n",
      "EUPHEMISM               0.333    0.600    0.429        5\n",
      "FALSE ASSERTION         0.000    0.000    0.000        9\n",
      "HYPERBOLE               1.000    0.167    0.286        6\n",
      "OTHER                   0.000    0.000    0.000       12\n",
      "OXYMORON                0.000    0.000    0.000        2\n",
      "RHETORICAL QUESTION     0.304    0.700    0.424       10\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.250    0.226    0.188       82\n",
      "weighted avg            0.288    0.256    0.229       82\n",
      "Accuracy                                           0.256\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'generation_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.263    0.556    0.357        9\n",
      "CONTEXT SHIFT           0.200    0.167    0.182       18\n",
      "EUPHEMISM               0.333    0.500    0.400        6\n",
      "FALSE ASSERTION         1.000    0.091    0.167       11\n",
      "HYPERBOLE               1.000    0.111    0.200        9\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.435    0.769    0.556       13\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.359    0.244    0.207       82\n",
      "weighted avg            0.410    0.280    0.241       82\n",
      "Accuracy                                           0.280\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.316    0.353    0.333       17\n",
      "CONTEXT SHIFT           0.467    0.250    0.326       28\n",
      "EUPHEMISM               0.444    0.286    0.348       14\n",
      "FALSE ASSERTION         0.000    0.000    0.000        4\n",
      "HYPERBOLE               1.000    0.250    0.400        4\n",
      "OTHER                   0.000    0.000    0.000        3\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.304    0.636    0.412       11\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.281    0.197    0.202       82\n",
      "weighted avg            0.390    0.305    0.314       82\n",
      "Accuracy                                           0.305\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.316    0.545    0.400       11\n",
      "CONTEXT SHIFT           0.200    0.176    0.188       17\n",
      "EUPHEMISM               0.333    0.750    0.462        4\n",
      "FALSE ASSERTION         1.000    0.067    0.125       15\n",
      "HYPERBOLE               1.000    0.125    0.222        8\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.125    0.200    0.154        5\n",
      "RHETORICAL QUESTION     0.261    0.857    0.400        7\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.359    0.302    0.217       82\n",
      "weighted avg            0.410    0.256    0.203       82\n",
      "Accuracy                                           0.256\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.263    0.312    0.286       16\n",
      "CONTEXT SHIFT           0.267    0.222    0.242       18\n",
      "EUPHEMISM               0.111    0.143    0.125        7\n",
      "FALSE ASSERTION         0.000    0.000    0.000       19\n",
      "HYPERBOLE               1.000    0.100    0.182       10\n",
      "OTHER                   0.000    0.000    0.000        6\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.217    1.000    0.357        5\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.206    0.198    0.132       82\n",
      "weighted avg            0.255    0.195    0.164       82\n",
      "Accuracy                                           0.195\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.263    0.556    0.357        9\n",
      "CONTEXT SHIFT           0.200    0.167    0.182       18\n",
      "EUPHEMISM               0.333    0.500    0.400        6\n",
      "FALSE ASSERTION         1.000    0.091    0.167       11\n",
      "HYPERBOLE               1.000    0.111    0.200        9\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.435    0.769    0.556       13\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.359    0.244    0.207       82\n",
      "weighted avg            0.410    0.280    0.241       82\n",
      "Accuracy                                           0.280\n",
      "\n",
      "ðŸ“Š Report per il modello 'Llama-3.1-8B-Instruct_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.368    0.467    0.412       15\n",
      "CONTEXT SHIFT           0.067    0.111    0.083        9\n",
      "EUPHEMISM               0.333    0.429    0.375        7\n",
      "FALSE ASSERTION         1.000    0.071    0.133       14\n",
      "HYPERBOLE               1.000    0.091    0.167       11\n",
      "OTHER                   0.000    0.000    0.000       14\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.348    0.727    0.471       11\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.346    0.211    0.182       82\n",
      "weighted avg            0.455    0.256    0.225       82\n",
      "Accuracy                                           0.256\n",
      "Processing model: Minerva-7B-instruct-v1.0_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.167    0.167    0.167       12\n",
      "CONTEXT SHIFT           0.355    0.423    0.386       26\n",
      "EUPHEMISM               0.000    0.000    0.000        5\n",
      "FALSE ASSERTION         0.250    0.222    0.235        9\n",
      "HYPERBOLE               0.000    0.000    0.000        6\n",
      "OTHER                   1.000    0.083    0.154       12\n",
      "OXYMORON                0.000    0.000    0.000        2\n",
      "RHETORICAL QUESTION     0.143    0.100    0.118       10\n",
      "macro avg               0.239    0.124    0.132       82\n",
      "weighted avg            0.328    0.207    0.209       82\n",
      "Accuracy                                           0.207\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'generation_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.333    0.444    0.381        9\n",
      "CONTEXT SHIFT           0.258    0.444    0.327       18\n",
      "EUPHEMISM               0.000    0.000    0.000        6\n",
      "FALSE ASSERTION         0.000    0.000    0.000       11\n",
      "HYPERBOLE               0.333    0.111    0.167        9\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.429    0.231    0.300       13\n",
      "macro avg               0.169    0.154    0.147       82\n",
      "weighted avg            0.198    0.195    0.179       82\n",
      "Accuracy                                           0.195\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.417    0.294    0.345       17\n",
      "CONTEXT SHIFT           0.355    0.393    0.373       28\n",
      "EUPHEMISM               0.500    0.071    0.125       14\n",
      "FALSE ASSERTION         0.000    0.000    0.000        4\n",
      "HYPERBOLE               0.000    0.000    0.000        4\n",
      "OTHER                   0.000    0.000    0.000        3\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.429    0.273    0.333       11\n",
      "macro avg               0.213    0.129    0.147       82\n",
      "weighted avg            0.350    0.244    0.265       82\n",
      "Accuracy                                           0.244\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.333    0.364    0.348       11\n",
      "CONTEXT SHIFT           0.290    0.529    0.375       17\n",
      "EUPHEMISM               0.000    0.000    0.000        4\n",
      "FALSE ASSERTION         0.250    0.133    0.174       15\n",
      "HYPERBOLE               0.000    0.000    0.000        8\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.111    0.400    0.174        5\n",
      "RHETORICAL QUESTION     0.286    0.286    0.286        7\n",
      "macro avg               0.159    0.214    0.170       82\n",
      "weighted avg            0.182    0.232    0.191       82\n",
      "Accuracy                                           0.232\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.333    0.250    0.286       16\n",
      "CONTEXT SHIFT           0.258    0.444    0.327       18\n",
      "EUPHEMISM               0.000    0.000    0.000        7\n",
      "FALSE ASSERTION         0.125    0.053    0.074       19\n",
      "HYPERBOLE               0.333    0.100    0.154       10\n",
      "OTHER                   0.000    0.000    0.000        6\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.143    0.200    0.167        5\n",
      "macro avg               0.149    0.131    0.126       82\n",
      "weighted avg            0.200    0.183    0.174       82\n",
      "Accuracy                                           0.183\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.333    0.444    0.381        9\n",
      "CONTEXT SHIFT           0.258    0.444    0.327       18\n",
      "EUPHEMISM               0.000    0.000    0.000        6\n",
      "FALSE ASSERTION         0.000    0.000    0.000       11\n",
      "HYPERBOLE               0.333    0.111    0.167        9\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.429    0.231    0.300       13\n",
      "macro avg               0.169    0.154    0.147       82\n",
      "weighted avg            0.198    0.195    0.179       82\n",
      "Accuracy                                           0.195\n",
      "\n",
      "ðŸ“Š Report per il modello 'Minerva-7B-instruct-v1.0_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.583    0.467    0.519       15\n",
      "CONTEXT SHIFT           0.097    0.333    0.150        9\n",
      "EUPHEMISM               0.000    0.000    0.000        7\n",
      "FALSE ASSERTION         0.125    0.071    0.091       14\n",
      "HYPERBOLE               0.667    0.182    0.286       11\n",
      "OTHER                   0.000    0.000    0.000       14\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.571    0.364    0.444       11\n",
      "macro avg               0.255    0.177    0.186       82\n",
      "weighted avg            0.305    0.207    0.225       82\n",
      "Accuracy                                           0.207\n",
      "Processing model: Ministral-8B-Instruct-2410-decoding-1 .csv_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410-decoding-1 .csv_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.333    0.667    0.444       12\n",
      "CONTEXT SHIFT           0.500    0.038    0.071       26\n",
      "EUPHEMISM               0.250    0.600    0.353        5\n",
      "FALSE ASSERTION         0.500    0.333    0.400        9\n",
      "HYPERBOLE               0.250    0.167    0.200        6\n",
      "IM:OFFENSIVE LANGUAGE    0.000    0.000    0.000        0\n",
      "IM:RHETORICAL DEVICE    0.000    0.000    0.000        0\n",
      "OTHER                   0.571    0.333    0.421       12\n",
      "OXYMORON                0.000    0.000    0.000        2\n",
      "RHETORICAL QUESTION     0.450    0.900    0.600       10\n",
      "SATIRIC HUMOR           0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.238    0.253    0.207       82\n",
      "weighted avg            0.434    0.354    0.303       82\n",
      "Accuracy                                           0.354\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410-decoding-1 .csv_predictions.csv' con file 'generation_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.292    0.778    0.424        9\n",
      "CONTEXT SHIFT           0.500    0.056    0.100       18\n",
      "EUPHEMISM               0.417    0.833    0.556        6\n",
      "FALSE ASSERTION         0.500    0.273    0.353       11\n",
      "HYPERBOLE               0.250    0.111    0.154        9\n",
      "IM:OFFENSIVE LANGUAGE    0.000    0.000    0.000        0\n",
      "IM:RHETORICAL DEVICE    0.000    0.000    0.000        0\n",
      "OTHER                   0.429    0.200    0.273       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.550    0.846    0.667       13\n",
      "SATIRIC HUMOR           0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.245    0.258    0.210       82\n",
      "weighted avg            0.432    0.378    0.329       82\n",
      "Accuracy                                           0.378\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410-decoding-1 .csv_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.458    0.647    0.537       17\n",
      "CONTEXT SHIFT           0.500    0.036    0.067       28\n",
      "EUPHEMISM               0.583    0.500    0.538       14\n",
      "FALSE ASSERTION         0.000    0.000    0.000        4\n",
      "HYPERBOLE               0.250    0.250    0.250        4\n",
      "IM:OFFENSIVE LANGUAGE    0.000    0.000    0.000        0\n",
      "IM:RHETORICAL DEVICE    0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000        3\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.400    0.727    0.516       11\n",
      "SATIRIC HUMOR           0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.183    0.180    0.159       82\n",
      "weighted avg            0.431    0.341    0.307       82\n",
      "Accuracy                                           0.341\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410-decoding-1 .csv_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.333    0.727    0.457       11\n",
      "CONTEXT SHIFT           0.500    0.059    0.105       17\n",
      "EUPHEMISM               0.250    0.750    0.375        4\n",
      "FALSE ASSERTION         0.667    0.267    0.381       15\n",
      "HYPERBOLE               0.750    0.375    0.500        8\n",
      "IM:OFFENSIVE LANGUAGE    0.000    0.000    0.000        0\n",
      "IM:RHETORICAL DEVICE    0.000    0.000    0.000        0\n",
      "OTHER                   0.143    0.067    0.091       15\n",
      "OXYMORON                0.000    0.000    0.000        5\n",
      "RHETORICAL QUESTION     0.300    0.857    0.444        7\n",
      "SATIRIC HUMOR           0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.245    0.258    0.196       82\n",
      "weighted avg            0.407    0.317    0.274       82\n",
      "Accuracy                                           0.317\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410-decoding-1 .csv_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.417    0.625    0.500       16\n",
      "CONTEXT SHIFT           0.000    0.000    0.000       18\n",
      "EUPHEMISM               0.250    0.429    0.316        7\n",
      "FALSE ASSERTION         0.333    0.105    0.160       19\n",
      "HYPERBOLE               0.250    0.100    0.143       10\n",
      "IM:OFFENSIVE LANGUAGE    0.000    0.000    0.000        0\n",
      "IM:RHETORICAL DEVICE    0.000    0.000    0.000        0\n",
      "OTHER                   0.571    0.667    0.615        6\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.250    1.000    0.400        5\n",
      "SATIRIC HUMOR           0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.173    0.244    0.178       82\n",
      "weighted avg            0.267    0.305    0.248       82\n",
      "Accuracy                                           0.305\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410-decoding-1 .csv_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.292    0.778    0.424        9\n",
      "CONTEXT SHIFT           0.500    0.056    0.100       18\n",
      "EUPHEMISM               0.417    0.833    0.556        6\n",
      "FALSE ASSERTION         0.500    0.273    0.353       11\n",
      "HYPERBOLE               0.250    0.111    0.154        9\n",
      "IM:OFFENSIVE LANGUAGE    0.000    0.000    0.000        0\n",
      "IM:RHETORICAL DEVICE    0.000    0.000    0.000        0\n",
      "OTHER                   0.429    0.200    0.273       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.550    0.846    0.667       13\n",
      "SATIRIC HUMOR           0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.245    0.258    0.210       82\n",
      "weighted avg            0.432    0.378    0.329       82\n",
      "Accuracy                                           0.378\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410-decoding-1 .csv_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.375    0.600    0.462       15\n",
      "CONTEXT SHIFT           0.000    0.000    0.000        9\n",
      "EUPHEMISM               0.333    0.571    0.421        7\n",
      "FALSE ASSERTION         0.500    0.214    0.300       14\n",
      "HYPERBOLE               0.250    0.091    0.133       11\n",
      "IM:OFFENSIVE LANGUAGE    0.000    0.000    0.000        0\n",
      "IM:RHETORICAL DEVICE    0.000    0.000    0.000        0\n",
      "OTHER                   0.286    0.143    0.190       14\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.500    0.909    0.645       11\n",
      "SATIRIC HUMOR           0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.187    0.211    0.179       82\n",
      "weighted avg            0.332    0.354    0.309       82\n",
      "Accuracy                                           0.354\n",
      "Processing model: Ministral-8B-Instruct-2410_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.333    0.333    0.333       12\n",
      "CONTEXT SHIFT           0.250    0.269    0.259       26\n",
      "EUPHEMISM               0.500    0.200    0.286        5\n",
      "FALSE ASSERTION         0.286    0.222    0.250        9\n",
      "HYPERBOLE               0.000    0.000    0.000        6\n",
      "OTHER                   0.800    0.333    0.471       12\n",
      "OXYMORON                0.000    0.000    0.000        2\n",
      "RHETORICAL QUESTION     0.333    0.300    0.316       10\n",
      "macro avg               0.313    0.207    0.239       82\n",
      "weighted avg            0.348    0.256    0.283       82\n",
      "Accuracy                                           0.256\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'generation_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.417    0.556    0.476        9\n",
      "CONTEXT SHIFT           0.179    0.278    0.217       18\n",
      "EUPHEMISM               0.500    0.167    0.250        6\n",
      "FALSE ASSERTION         0.286    0.182    0.222       11\n",
      "HYPERBOLE               0.000    0.000    0.000        9\n",
      "OTHER                   0.600    0.200    0.300       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.333    0.231    0.273       13\n",
      "macro avg               0.289    0.202    0.217       82\n",
      "weighted avg            0.322    0.232    0.246       82\n",
      "Accuracy                                           0.232\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.417    0.294    0.345       17\n",
      "CONTEXT SHIFT           0.286    0.286    0.286       28\n",
      "EUPHEMISM               0.500    0.071    0.125       14\n",
      "FALSE ASSERTION         0.143    0.250    0.182        4\n",
      "HYPERBOLE               0.000    0.000    0.000        4\n",
      "OTHER                   0.200    0.333    0.250        3\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.222    0.182    0.200       11\n",
      "macro avg               0.221    0.177    0.173       82\n",
      "weighted avg            0.313    0.220    0.235       82\n",
      "Accuracy                                           0.220\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.417    0.455    0.435       11\n",
      "CONTEXT SHIFT           0.250    0.412    0.311       17\n",
      "EUPHEMISM               0.500    0.250    0.333        4\n",
      "FALSE ASSERTION         0.429    0.200    0.273       15\n",
      "HYPERBOLE               0.000    0.000    0.000        8\n",
      "OTHER                   0.400    0.133    0.200       15\n",
      "OXYMORON                0.105    0.400    0.167        5\n",
      "RHETORICAL QUESTION     0.222    0.286    0.250        7\n",
      "macro avg               0.290    0.267    0.246       82\n",
      "weighted avg            0.309    0.268    0.257       82\n",
      "Accuracy                                           0.268\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.500    0.375    0.429       16\n",
      "CONTEXT SHIFT           0.179    0.278    0.217       18\n",
      "EUPHEMISM               0.000    0.000    0.000        7\n",
      "FALSE ASSERTION         0.286    0.105    0.154       19\n",
      "HYPERBOLE               0.000    0.000    0.000       10\n",
      "OTHER                   0.400    0.333    0.364        6\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.111    0.200    0.143        5\n",
      "macro avg               0.184    0.161    0.163       82\n",
      "weighted avg            0.239    0.195    0.202       82\n",
      "Accuracy                                           0.195\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.417    0.556    0.476        9\n",
      "CONTEXT SHIFT           0.179    0.278    0.217       18\n",
      "EUPHEMISM               0.500    0.167    0.250        6\n",
      "FALSE ASSERTION         0.286    0.182    0.222       11\n",
      "HYPERBOLE               0.000    0.000    0.000        9\n",
      "OTHER                   0.600    0.200    0.300       15\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "RHETORICAL QUESTION     0.333    0.231    0.273       13\n",
      "macro avg               0.289    0.202    0.217       82\n",
      "weighted avg            0.322    0.232    0.246       82\n",
      "Accuracy                                           0.232\n",
      "\n",
      "ðŸ“Š Report per il modello 'Ministral-8B-Instruct-2410_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.583    0.467    0.519       15\n",
      "CONTEXT SHIFT           0.143    0.444    0.216        9\n",
      "EUPHEMISM               0.500    0.143    0.222        7\n",
      "FALSE ASSERTION         0.286    0.143    0.190       14\n",
      "HYPERBOLE               0.000    0.000    0.000       11\n",
      "OTHER                   0.400    0.143    0.211       14\n",
      "OXYMORON                0.053    1.000    0.100        1\n",
      "RHETORICAL QUESTION     0.333    0.273    0.300       11\n",
      "macro avg               0.287    0.327    0.220       82\n",
      "weighted avg            0.328    0.244    0.247       82\n",
      "Accuracy                                           0.244\n",
      "Processing model: Qwen2.5-7B-Instruct_predictions.csv\n",
      "\n",
      "ðŸ“Š Report per il modello 'Qwen2.5-7B-Instruct_predictions.csv' con file 'female_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.000    0.000    0.000       12\n",
      "CONTEXT SHIFT           0.333    0.038    0.069       26\n",
      "EUPHEMISM               0.000    0.000    0.000        5\n",
      "EX:CONTRAST             0.000    0.000    0.000        0\n",
      "EXPLAIN: THE FIGURES ARE CLEARLY OPPOSITE AND ARE ABSTRACT THINGS    0.000    0.000    0.000        0\n",
      "EXPLAIN:OXYMORON FIGURES    0.000    0.000    0.000        0\n",
      "FALSE ASSERTION         0.000    0.000    0.000        9\n",
      "HYPERBOLE               0.000    0.000    0.000        6\n",
      "MINOR PREMISE ABSENT    0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       12\n",
      "OXYMORON                0.062    0.500    0.111        2\n",
      "PARADOX                 0.000    0.000    0.000        0\n",
      "RHETORICAL QUESTION     0.000    0.000    0.000       10\n",
      "VERBAL IRRITY. THAT'S WHY IS AN EXAMPLE OF VERBAL IRRITY    0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.026    0.036    0.012       82\n",
      "weighted avg            0.107    0.024    0.025       82\n",
      "Accuracy                                           0.024\n",
      "\n",
      "ðŸ“Š Report per il modello 'Qwen2.5-7B-Instruct_predictions.csv' con file 'generation_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.000    0.000    0.000        9\n",
      "CONTEXT SHIFT           0.000    0.000    0.000       18\n",
      "EUPHEMISM               0.000    0.000    0.000        6\n",
      "EX:CONTRAST             0.000    0.000    0.000        0\n",
      "EXPLAIN: THE FIGURES ARE CLEARLY OPPOSITE AND ARE ABSTRACT THINGS    0.000    0.000    0.000        0\n",
      "EXPLAIN:OXYMORON FIGURES    0.000    0.000    0.000        0\n",
      "FALSE ASSERTION         0.000    0.000    0.000       11\n",
      "HYPERBOLE               0.000    0.000    0.000        9\n",
      "MINOR PREMISE ABSENT    0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.062    1.000    0.118        1\n",
      "PARADOX                 0.000    0.000    0.000        0\n",
      "RHETORICAL QUESTION     0.000    0.000    0.000       13\n",
      "VERBAL IRRITY. THAT'S WHY IS AN EXAMPLE OF VERBAL IRRITY    0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.004    0.067    0.008       82\n",
      "weighted avg            0.001    0.012    0.001       82\n",
      "Accuracy                                           0.012\n",
      "\n",
      "ðŸ“Š Report per il modello 'Qwen2.5-7B-Instruct_predictions.csv' con file 'genx_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.000    0.000    0.000       17\n",
      "CONTEXT SHIFT           0.333    0.036    0.065       28\n",
      "EUPHEMISM               0.000    0.000    0.000       14\n",
      "EX:CONTRAST             0.000    0.000    0.000        0\n",
      "EXPLAIN: THE FIGURES ARE CLEARLY OPPOSITE AND ARE ABSTRACT THINGS    0.000    0.000    0.000        0\n",
      "EXPLAIN:OXYMORON FIGURES    0.000    0.000    0.000        0\n",
      "FALSE ASSERTION         0.000    0.000    0.000        4\n",
      "HYPERBOLE               0.000    0.000    0.000        4\n",
      "MINOR PREMISE ABSENT    0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000        3\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "PARADOX                 0.000    0.000    0.000        0\n",
      "RHETORICAL QUESTION     0.500    0.091    0.154       11\n",
      "VERBAL IRRITY. THAT'S WHY IS AN EXAMPLE OF VERBAL IRRITY    0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.056    0.008    0.015       82\n",
      "weighted avg            0.181    0.024    0.043       82\n",
      "Accuracy                                           0.024\n",
      "\n",
      "ðŸ“Š Report per il modello 'Qwen2.5-7B-Instruct_predictions.csv' con file 'geny_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.000    0.000    0.000       11\n",
      "CONTEXT SHIFT           0.000    0.000    0.000       17\n",
      "EUPHEMISM               0.000    0.000    0.000        4\n",
      "EX:CONTRAST             0.000    0.000    0.000        0\n",
      "EXPLAIN: THE FIGURES ARE CLEARLY OPPOSITE AND ARE ABSTRACT THINGS    0.000    0.000    0.000        0\n",
      "EXPLAIN:OXYMORON FIGURES    0.000    0.000    0.000        0\n",
      "FALSE ASSERTION         0.000    0.000    0.000       15\n",
      "HYPERBOLE               0.000    0.000    0.000        8\n",
      "MINOR PREMISE ABSENT    0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.062    0.200    0.095        5\n",
      "PARADOX                 0.000    0.000    0.000        0\n",
      "RHETORICAL QUESTION     0.500    0.143    0.222        7\n",
      "VERBAL IRRITY. THAT'S WHY IS AN EXAMPLE OF VERBAL IRRITY    0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.037    0.023    0.021       82\n",
      "weighted avg            0.046    0.024    0.025       82\n",
      "Accuracy                                           0.024\n",
      "\n",
      "ðŸ“Š Report per il modello 'Qwen2.5-7B-Instruct_predictions.csv' con file 'genz_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.000    0.000    0.000       16\n",
      "CONTEXT SHIFT           0.333    0.056    0.095       18\n",
      "EUPHEMISM               0.000    0.000    0.000        7\n",
      "EX:CONTRAST             0.000    0.000    0.000        0\n",
      "EXPLAIN: THE FIGURES ARE CLEARLY OPPOSITE AND ARE ABSTRACT THINGS    0.000    0.000    0.000        0\n",
      "EXPLAIN:OXYMORON FIGURES    0.000    0.000    0.000        0\n",
      "FALSE ASSERTION         0.000    0.000    0.000       19\n",
      "HYPERBOLE               0.000    0.000    0.000       10\n",
      "MINOR PREMISE ABSENT    0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000        6\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "PARADOX                 0.000    0.000    0.000        0\n",
      "RHETORICAL QUESTION     0.000    0.000    0.000        5\n",
      "VERBAL IRRITY. THAT'S WHY IS AN EXAMPLE OF VERBAL IRRITY    0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.022    0.004    0.006       82\n",
      "weighted avg            0.073    0.012    0.021       82\n",
      "Accuracy                                           0.012\n",
      "\n",
      "ðŸ“Š Report per il modello 'Qwen2.5-7B-Instruct_predictions.csv' con file 'global_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.000    0.000    0.000        9\n",
      "CONTEXT SHIFT           0.000    0.000    0.000       18\n",
      "EUPHEMISM               0.000    0.000    0.000        6\n",
      "EX:CONTRAST             0.000    0.000    0.000        0\n",
      "EXPLAIN: THE FIGURES ARE CLEARLY OPPOSITE AND ARE ABSTRACT THINGS    0.000    0.000    0.000        0\n",
      "EXPLAIN:OXYMORON FIGURES    0.000    0.000    0.000        0\n",
      "FALSE ASSERTION         0.000    0.000    0.000       11\n",
      "HYPERBOLE               0.000    0.000    0.000        9\n",
      "MINOR PREMISE ABSENT    0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       15\n",
      "OXYMORON                0.062    1.000    0.118        1\n",
      "PARADOX                 0.000    0.000    0.000        0\n",
      "RHETORICAL QUESTION     0.000    0.000    0.000       13\n",
      "VERBAL IRRITY. THAT'S WHY IS AN EXAMPLE OF VERBAL IRRITY    0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.004    0.067    0.008       82\n",
      "weighted avg            0.001    0.012    0.001       82\n",
      "Accuracy                                           0.012\n",
      "\n",
      "ðŸ“Š Report per il modello 'Qwen2.5-7B-Instruct_predictions.csv' con file 'male_actual_labels.csv':\n",
      "\n",
      "ðŸ“ˆ Report di classificazione (precision, recall, f1-score, support):\n",
      "Label                    Prec      Rec       F1  Support\n",
      "--------------------------------------------------------\n",
      "ANALOGY                 0.000    0.000    0.000       15\n",
      "CONTEXT SHIFT           0.000    0.000    0.000        9\n",
      "EUPHEMISM               0.000    0.000    0.000        7\n",
      "EX:CONTRAST             0.000    0.000    0.000        0\n",
      "EXPLAIN: THE FIGURES ARE CLEARLY OPPOSITE AND ARE ABSTRACT THINGS    0.000    0.000    0.000        0\n",
      "EXPLAIN:OXYMORON FIGURES    0.000    0.000    0.000        0\n",
      "FALSE ASSERTION         0.000    0.000    0.000       14\n",
      "HYPERBOLE               0.000    0.000    0.000       11\n",
      "MINOR PREMISE ABSENT    0.000    0.000    0.000        0\n",
      "OTHER                   0.000    0.000    0.000       14\n",
      "OXYMORON                0.000    0.000    0.000        1\n",
      "PARADOX                 0.000    0.000    0.000        0\n",
      "RHETORICAL QUESTION     0.500    0.091    0.154       11\n",
      "VERBAL IRRITY. THAT'S WHY IS AN EXAMPLE OF VERBAL IRRITY    0.000    0.000    0.000        0\n",
      "nan                     0.000    0.000    0.000        0\n",
      "macro avg               0.033    0.006    0.010       82\n",
      "weighted avg            0.067    0.012    0.021       82\n",
      "Accuracy                                           0.012\n"
     ]
    }
   ],
   "source": [
    "model_files = open_files('models_generations')\n",
    "actual_files = open_files('actuals')\n",
    "\n",
    "models = {}\n",
    "for model_file in model_files:\n",
    "    # estrai il nome modello rimuovendo pattern specifici\n",
    "    model_name = re.sub(r\"^(fine-tuned-)?|-decoding-\\d+\\.csv$\", \"\", model_file)\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "\n",
    "    model = pd.read_csv(os.path.join('models_generations', model_file))\n",
    "\n",
    "    reports = []\n",
    "    for actual_file in actual_files:\n",
    "        actual = pd.read_csv(os.path.join('actuals', actual_file))\n",
    "\n",
    "        # fai il join di actual e model, utilizzando la colonna \"pippo\" di actual e l'index di model\n",
    "        merged = pd.merge(actual, model, left_on='index', right_index=True, how='left')\n",
    "\n",
    "        print(f\"\\nðŸ“Š Report per il modello '{model_name}' con file '{actual_file}':\")\n",
    "        report = calculate_metrics(merged, print_confusion=False)\n",
    "        #print(report)\n",
    "        formatted_report = format_report(report)\n",
    "        print_formatted_report(formatted_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
