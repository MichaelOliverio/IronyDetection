{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installa spaCy e il modello italiano in Colab\n",
        "!pip install -U spacy\n",
        "!python -m spacy download it_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQEStit0h3Ai",
        "outputId": "0aeca704-d287-46d3-8c9e-84b8dbc49fa2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting it-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: it-core-news-sm\n",
            "Successfully installed it-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PyJX525ghcxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919bf70d-488d-4b36-fb6c-21ddae0021aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          generation  num_tokens       ttr  \\\n",
            "0  Ah, grazie per la lezione di economia. E per l...          11  0.818182   \n",
            "1              Buongiorno! Come posso aiutarti oggi?           5  1.000000   \n",
            "2  La tua paranoia è giustificata. Il mercato del...          45  0.866667   \n",
            "3                                   Output not found           3  1.000000   \n",
            "4  Se solo la società fosse così severa con tutti...          22  0.954545   \n",
            "\n",
            "   num_negations  num_interjections  \n",
            "0              0                  1  \n",
            "1              0                  0  \n",
            "2              2                  0  \n",
            "3              0                  0  \n",
            "4              0                  0  \n",
            "VALORI MEDI:\n",
            "Token totali medi:        20.173\n",
            "TTR medio:                0.938\n",
            "Numero medio negazioni:  0.381\n",
            "Numero medio interiezioni: 0.410\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "# Carica modello spaCy italiano\n",
        "nlp = spacy.load(\"it_core_news_sm\")  # puoi usare anche 'it_core_news_lg' se hai bisogno di più accuratezza\n",
        "\n",
        "# Carica il file CSV\n",
        "df = pd.read_csv(\"multipico_generation.csv\")\n",
        "\n",
        "# Funzione per analizzare testo con spaCy\n",
        "def analyze_text(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text for token in doc if not token.is_punct and not token.is_space]\n",
        "    types = set(tokens)\n",
        "    ttr = len(types) / len(tokens) if tokens else 0\n",
        "\n",
        "    # Conta le negazioni (es. 'non', 'nessuno', 'mai', ecc.)\n",
        "    negations = [token for token in doc if token.dep_ == \"neg\" or token.lemma_ in [\"non\", \"nessuno\", \"mai\"]]\n",
        "\n",
        "    # Conta le interiezioni (INTJ)\n",
        "    interjections = [token for token in doc if token.pos_ == \"INTJ\"]\n",
        "\n",
        "    return len(tokens), ttr, len(negations), len(interjections)\n",
        "\n",
        "# Applica l'analisi spaCy riga per riga\n",
        "results = df[\"generation\"].apply(analyze_text)\n",
        "\n",
        "# Estrai i risultati in nuove colonne\n",
        "df[[\"num_tokens\", \"ttr\", \"num_negations\", \"num_interjections\"]] = pd.DataFrame(results.tolist(), index=df.index)\n",
        "\n",
        "# Salva il risultato in un nuovo CSV (opzionale)\n",
        "df.to_csv(\"multipico_generation_metrics.csv\", index=False)\n",
        "\n",
        "# Visualizza un estratto dei risultati\n",
        "print(df[[\"generation\", \"num_tokens\", \"ttr\", \"num_negations\", \"num_interjections\"]].head())\n",
        "\n",
        "# Calcola e stampa le medie delle metriche\n",
        "mean_tokens = df[\"num_tokens\"].mean()\n",
        "mean_ttr = df[\"ttr\"].mean()\n",
        "mean_negations = df[\"num_negations\"].mean()\n",
        "mean_interjections = df[\"num_interjections\"].mean()\n",
        "\n",
        "print(\"VALORI MEDI:\")\n",
        "print(f\"Token totali medi:        {mean_tokens:.3f}\")\n",
        "print(f\"TTR medio:                {mean_ttr:.3f}\")\n",
        "print(f\"Numero medio negazioni:  {mean_negations:.3f}\")\n",
        "print(f\"Numero medio interiezioni: {mean_interjections:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carica il file CSV\n",
        "df = pd.read_csv(\"multipico_generation-baseline_with_output.csv\")\n",
        "\n",
        "# Funzione per analizzare testo con spaCy\n",
        "def analyze_text(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text for token in doc if not token.is_punct and not token.is_space]\n",
        "    types = set(tokens)\n",
        "    ttr = len(types) / len(tokens) if tokens else 0\n",
        "\n",
        "    # Conta le negazioni (es. 'non', 'nessuno', 'mai', ecc.)\n",
        "    negations = [token for token in doc if token.dep_ == \"neg\" or token.lemma_ in [\"non\", \"nessuno\", \"mai\"]]\n",
        "\n",
        "    # Conta le interiezioni (INTJ)\n",
        "    interjections = [token for token in doc if token.pos_ == \"INTJ\"]\n",
        "\n",
        "    return len(tokens), ttr, len(negations), len(interjections)\n",
        "\n",
        "# Applica l'analisi spaCy riga per riga\n",
        "results = df[\"generation\"].apply(analyze_text)\n",
        "\n",
        "# Estrai i risultati in nuove colonne\n",
        "df[[\"num_tokens\", \"ttr\", \"num_negations\", \"num_interjections\"]] = pd.DataFrame(results.tolist(), index=df.index)\n",
        "\n",
        "# Salva il risultato in un nuovo CSV (opzionale)\n",
        "df.to_csv(\"multipico_generation_metrics.csv\", index=False)\n",
        "\n",
        "# Visualizza un estratto dei risultati\n",
        "print(df[[\"generation\", \"num_tokens\", \"ttr\", \"num_negations\", \"num_interjections\"]].head())\n",
        "\n",
        "# Calcola e stampa le medie delle metriche\n",
        "mean_tokens = df[\"num_tokens\"].mean()\n",
        "mean_ttr = df[\"ttr\"].mean()\n",
        "mean_negations = df[\"num_negations\"].mean()\n",
        "mean_interjections = df[\"num_interjections\"].mean()\n",
        "\n",
        "print(\"VALORI MEDI:\")\n",
        "print(f\"Token totali medi:        {mean_tokens:.3f}\")\n",
        "print(f\"TTR medio:                {mean_ttr:.3f}\")\n",
        "print(f\"Numero medio negazioni:  {mean_negations:.3f}\")\n",
        "print(f\"Numero medio interiezioni: {mean_interjections:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHY8Y3m6icks",
        "outputId": "debd494f-6f1d-42a5-fdef-fceb3a068d08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          generation  num_tokens       ttr  \\\n",
            "0  Ah, certo! E magari anche un bel regalo per il...          24  1.000000   \n",
            "1  Ah, finalmente un saluto che non mi fa sentire...          17  0.941176   \n",
            "2  Ah, il terrore di essere rimpiazzata! Non preo...          21  0.904762   \n",
            "3  \"Ah, quindi per la destra il lavoro è un favor...          17  0.941176   \n",
            "4  Ah, se solo la società fosse così efficiente n...          26  0.961538   \n",
            "\n",
            "   num_negations  num_interjections  \n",
            "0              0                  1  \n",
            "1              1                  1  \n",
            "2              1                  1  \n",
            "3              0                  1  \n",
            "4              0                  1  \n",
            "VALORI MEDI:\n",
            "Token totali medi:        22.399\n",
            "TTR medio:                0.935\n",
            "Numero medio negazioni:  0.507\n",
            "Numero medio interiezioni: 0.982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carica il file CSV\n",
        "df = pd.read_csv(\"multipico_ita_filtered.csv\")\n",
        "\n",
        "print(len(df))\n",
        "\n",
        "# Funzione per analizzare testo con spaCy\n",
        "def analyze_text(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.text for token in doc if not token.is_punct and not token.is_space]\n",
        "    types = set(tokens)\n",
        "    ttr = len(types) / len(tokens) if tokens else 0\n",
        "\n",
        "    # Conta le negazioni (es. 'non', 'nessuno', 'mai', ecc.)\n",
        "    negations = [token for token in doc if token.dep_ == \"neg\" or token.lemma_ in [\"non\", \"nessuno\", \"mai\"]]\n",
        "\n",
        "    # Conta le interiezioni (INTJ)\n",
        "    interjections = [token for token in doc if token.pos_ == \"INTJ\"]\n",
        "\n",
        "    return len(tokens), ttr, len(negations), len(interjections)\n",
        "\n",
        "# Applica l'analisi spaCy riga per riga\n",
        "results = df[\"reply\"].apply(analyze_text)\n",
        "\n",
        "# Estrai i risultati in nuove colonne\n",
        "df[[\"num_tokens\", \"ttr\", \"num_negations\", \"num_interjections\"]] = pd.DataFrame(results.tolist(), index=df.index)\n",
        "\n",
        "# Salva il risultato in un nuovo CSV (opzionale)\n",
        "df.to_csv(\"multipico_generation_metrics.csv\", index=False)\n",
        "\n",
        "# Visualizza un estratto dei risultati\n",
        "print(df[[\"reply\", \"num_tokens\", \"ttr\", \"num_negations\", \"num_interjections\"]].head())\n",
        "\n",
        "# Calcola e stampa le medie delle metriche\n",
        "mean_tokens = df[\"num_tokens\"].mean()\n",
        "mean_ttr = df[\"ttr\"].mean()\n",
        "mean_negations = df[\"num_negations\"].mean()\n",
        "mean_interjections = df[\"num_interjections\"].mean()\n",
        "\n",
        "print(\"VALORI MEDI:\")\n",
        "print(f\"Token totali medi:        {mean_tokens:.3f}\")\n",
        "print(f\"TTR medio:                {mean_ttr:.3f}\")\n",
        "print(f\"Numero medio negazioni:  {mean_negations:.3f}\")\n",
        "print(f\"Numero medio interiezioni: {mean_interjections:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xplpDGmXlT8c",
        "outputId": "39a648da-a7fd-42b6-bb68-7ac8b3718d42"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "278\n",
            "                                               reply  num_tokens       ttr  \\\n",
            "0         @USER  @USER Anche per rompere il ghiaccio           7  0.857143   \n",
            "1                     @USER Nonnino! Già sveglio? ??           4  1.000000   \n",
            "2             @USER il terrone di essere rimpiazzata           6  1.000000   \n",
            "3                  @USER Tanto per non essere banali           6  1.000000   \n",
            "4  Se le toghe rosse avessere mandato un avviso d...          19  0.947368   \n",
            "\n",
            "   num_negations  num_interjections  \n",
            "0              0                  0  \n",
            "1              0                  0  \n",
            "2              0                  0  \n",
            "3              1                  0  \n",
            "4              0                  0  \n",
            "VALORI MEDI:\n",
            "Token totali medi:        12.471\n",
            "TTR medio:                0.956\n",
            "Numero medio negazioni:  0.273\n",
            "Numero medio interiezioni: 0.072\n"
          ]
        }
      ]
    }
  ]
}